{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "env: MUJOCO_GL=egl\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env MUJOCO_GL=egl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://packagecloud.io/github/git-lfs/pypi/simple\n",
      "Requirement already satisfied: numpy in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (1.26.4)\n",
      "Requirement already satisfied: torch in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: wandb in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (0.17.0)\n",
      "Requirement already satisfied: swig in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (4.2.1)\n",
      "Requirement already satisfied: matplotlib in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (3.8.4)\n",
      "Requirement already satisfied: termcolor in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (2.4.0)\n",
      "Requirement already satisfied: gymnasium[mujoco] in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (0.29.1)\n",
      "Requirement already satisfied: filelock in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from torch) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from wandb) (4.2.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from wandb) (4.25.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from wandb) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from wandb) (2.1.1)\n",
      "Requirement already satisfied: setproctitle in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from wandb) (70.0.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from gymnasium[mujoco]) (3.0.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from gymnasium[mujoco]) (0.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from gymnasium[mujoco]) (7.1.0)\n",
      "Requirement already satisfied: mujoco>=2.3.3 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from gymnasium[mujoco]) (3.1.6)\n",
      "Requirement already satisfied: imageio>=2.14.1 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from gymnasium[mujoco]) (2.34.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from importlib-metadata>=4.8.0->gymnasium[mujoco]) (3.18.1)\n",
      "Requirement already satisfied: absl-py in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from mujoco>=2.3.3->gymnasium[mujoco]) (2.1.0)\n",
      "Requirement already satisfied: etils[epath] in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from mujoco>=2.3.3->gymnasium[mujoco]) (1.5.2)\n",
      "Requirement already satisfied: glfw in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from mujoco>=2.3.3->gymnasium[mujoco]) (2.7.0)\n",
      "Requirement already satisfied: pyopengl in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from mujoco>=2.3.3->gymnasium[mujoco]) (3.1.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/alex/anaconda3/envs/239as/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy torch wandb swig gymnasium[mujoco] matplotlib termcolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import test\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning Part 2: DDPG\n",
    "By Lawrence Liu\n",
    "## Some General Instructions\n",
    "- This entire assigment will be worth 5 points of extra credit for project 4, and will be due on the same day as project 4, so June 7th.\n",
    "- You will be implementing a DDPG agent to solve the DoublePendulum environment.\n",
    "- Because this is a bonus, there will be no test cases.\n",
    "- You will need to implement the TODOs in the `ddpg.py` and `model.py` files.\n",
    "DO NOT use Windows for this project, gymnasium does is not supported for windows and installing it will be difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to the Enviroment\n",
    "We will be training a DDPG agent to solve the DoublePendulum environment. The DoublePendulum environment is a classic control problem where the goal is to balance a double pendulum on a cart. \n",
    "#### Action Space\n",
    "The agent can apply a force to the cart in the range of -1 to 1. This is a continuous action space.\n",
    "#### Observation Space\n",
    "The observation space is a 11 dimensional vector. The first 1 is the position of the cart, the next 4 are the cosines and sins of different angles of the double pendulum, and the next 3 are the velocities of the cart and the pendulum, and the final 3 are the constrain forces on the pendulum. You can find more information about these constraint forces [here](https://homes.cs.washington.edu/~todorov/papers/TodorovICRA14.pdf) \n",
    "#### Reward\n",
    "The reward can be decomposed into 3 parts. The first part is an alive bonus that pays +10 for every time step the second pendulum is upright. There are 2 penalty terms, one for the tip of the second pendulum moving too much, and another for the cart moving too fast.\n",
    "\n",
    "You can find more information about the environment [here](https://gymnasium.farama.org/environments/mujoco/inverted_double_pendulum/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "env = gym.make(\"InvertedDoublePendulum-v4\")\n",
    "env.np_random = np.random.RandomState(42)\n",
    "\n",
    "eval_env = gym.make(\"InvertedDoublePendulum-v4\", render_mode=\"rgb_array\")\n",
    "eval_env.np_random = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "frames = []\n",
    "s, _ = eval_env.reset()\n",
    "\n",
    "while True:\n",
    "    a = eval_env.action_space.sample()\n",
    "    s, r, terminated, truncated, _ = eval_env.step(a)\n",
    "    frames.append(eval_env.render())\n",
    "    if terminated or truncated:\n",
    "        break\n",
    "\n",
    "\n",
    "anim = animate(frames)\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model (1 point)\n",
    "Because the inputs to the model is a 11 dimensional vector, we will use a MLP. Specifically we will follow the architecture in the DDPG paper. For DDPG we have both an Actor and a Critic. The Actor is responsible for selecting the action, and the Critic is responsible for evaluating the action. \n",
    "#### Actor\n",
    "The Actor is a 3 layer MLP:\n",
    "- Layer 1: 400 units, ReLU activation, Fan-in weight initialization, ie each weight is initialized with a uniform distribution in the range of -1/sqrt(fan_in) to 1/sqrt(fan_in)\n",
    "- Layer 2: 300 units, ReLU activation, Fan-in weight initialization, ie each weight is initialized with a uniform distribution in the range of -1/sqrt(fan_in) to 1/sqrt(fan_in)\n",
    "- Layer 3: 1 unit, tanh activation, intialized with uniform weights in the range of -0.003 to 0.003\n",
    "#### Critic\n",
    "The Critic is a 3 layer MLP:\n",
    "- Layer 1: 400 units, ReLU activation, Fan-in weight initialization, ie each weight is initialized with a uniform distribution in the range of -1/sqrt(fan_in) to 1/sqrt(fan_in)\n",
    "- Layer 2: 300 units, ReLU activation, Fan-in weight initialization, ie each weight is initialized with a uniform distribution in the range of -1/sqrt(fan_in) to 1/sqrt(fan_in). Input is the concatenation of the 400 dimension embedding from the state, and the action taken.\n",
    "- Layer 3: 1 unit, intialized with uniform weights in the range of -0.003 to 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration (1 point)\n",
    "Because DDPG is an off policy algorithm, we will use a noise process to encourage exploration. Specifically we will use the Ornstein-Uhlenbeck process. The Ornstein-Uhlenbeck process is a stochastic process that generates temporally correlated noise. The process is defined by the following stochastic differential equation:\n",
    "$$dx_t = \\theta(\\mu - x_t)dt + \\sigma dW_t$$\n",
    "Where $\\theta$ is the rate of mean reversion, $\\mu$ is the long run mean of the process, $\\sigma$ is the volatility of the process, and $W_t$ is a Wiener process. We can discretize this process to get the following:\n",
    "$$x_{t+1} = x_t + \\theta(\\mu - x_t)dt + \\sigma \\sqrt{dt}\\mathcal{N}(0,1)$$\n",
    "Where $N(0,1)$ is a sample from the standard normal distribution. We will asume that our steps are of unit length, so we can simplify this to:\n",
    "$$x_{t+1} = x_t + \\theta(\\mu - x_t) + \\sigma \\mathcal{N}(0,1)$$\n",
    "We will use $\\theta = 0.15$, $\\mu = 0$, and $\\sigma = 0.2$. We will add this to our action in the following way\n",
    "$$a_t = \\min(\\max(\\mu(s_t) + x_t, -1), 1)$$\n",
    "Where $a_t$ is the action taken by the agent, $\\mu(s_t)$ is the action selected by the actor, and $x_t$ is the noise generated by the Ornstein-Uhlenbeck process.\n",
    "Please implement the `OU_Noise` class in DDPG.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDPG (3 points total)\n",
    "We will be implementing the DDPG algorithm. The DDPG algorithm is a model free, off policy algorithm that combines the actor-critic architecture with the insights of DQN. The algorithm is as follows:\n",
    "![DDPG](DDPG.png)\n",
    "Fill in the TODOs in the `DDPG` class in DDPG.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DDPG\n",
    "import utils\n",
    "t = DDPG.DDPG(env,\n",
    "            model.Actor,\n",
    "            model.Critic,\n",
    "            use_wandb=True,\n",
    "            save_path = utils.get_save_path(\"DDPG\",\"./runs/\"))\n",
    "\n",
    "t.train(10000,\n",
    "        100,\n",
    "        100,\n",
    "        1000,\n",
    "        100,\n",
    "        1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like what we did for the DQN, we can also animate one episode of the agent in the DoublePendulum environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rewards, frames = t.play_episode(0,True,42,eval_env)\n",
    "anim = animate(frames,max_frames = 1000)\n",
    "print(total_rewards)\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the agent is able to balance the double pendulum and it eventually reaches the equilibrium. However this equilibrium is not a stable equilibrium, so lets see how this model performs with perturbations. To do this, we will perturbe the model every 49 steps with a large input of $\\pm 0.75$ N to the cart. We will see how the model performs with this perturbation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "frames = []\n",
    "scores = 0\n",
    "(s, _), done, ret = eval_env.reset(seed = 42\n",
    "                                   ), False, 0\n",
    "t.actor.eval()\n",
    "S = []\n",
    "outputs = []\n",
    "# s, r, terminated, truncated, info = eval_env.step(3)\n",
    "i = 0\n",
    "with torch.no_grad():\n",
    "    while not done:\n",
    "        # if random.random() < 0.1:\n",
    "        #     action = random.randint(0,4)\n",
    "        # else:\n",
    "        frames.append(eval_env.render())\n",
    "        output = t.actor(torch.tensor(s).unsqueeze(0).to(\"cpu\").float())\n",
    "        i+=1\n",
    "        if i%50 == 49:\n",
    "            output += 0.75*(np.sign(torch.randn_like(output)))\n",
    "        s_prime, r, terminated, truncated, info = eval_env.step(output.cpu().numpy().squeeze(0))\n",
    "        s = s_prime\n",
    "        ret += r\n",
    "        done = terminated or truncated\n",
    "        \n",
    "scores += ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim = animate(frames,max_frames = 500)\n",
    "print(total_rewards)\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that the model is able to recover from the perturbation and is able to balance the double pendulum."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
